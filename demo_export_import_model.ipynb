{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting / Importing trained MaskRCNN model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import numpy as np\n",
    "import imageio\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import graph_util\n",
    "from keras import backend as K\n",
    "\n",
    "from config import Config\n",
    "from inference_config import inference_config\n",
    "import model as modellib\n",
    "import utils\n",
    "import visualize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting model\n",
    "After retrain the model using train.py, we export the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\Mask\\def_single\\logs\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Root directory of the project\n",
    "ROOT_DIR = os.getcwd()\n",
    "# Directory to trained model\n",
    "train_log_dirpath = os.path.join(ROOT_DIR, \"logs\")\n",
    "print(train_log_dirpath)\n",
    "model_filepath = None# os.path.join(ROOT_DIR, \"logs\",\"trained_model\",\"my_model.h5\")\n",
    "print(model_filepath)\n",
    "# name of the pb file we want to output\n",
    "filename = 'mask_rcnn_New.pb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE_SHAPES                [[128 128]\n",
      " [ 64  64]\n",
      " [ 32  32]\n",
      " [ 16  16]\n",
      " [  8   8]]\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "DETECTION_MAX_INSTANCES        50\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "GPU_COUNT                      1\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_MAX_DIM                  512\n",
      "IMAGE_MIN_DIM                  512\n",
      "IMAGE_PADDING                  True\n",
      "IMAGE_SHAPE                    [512 512   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           myConfig\n",
      "NUM_CLASSES                    2\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "RESNET_ARCHITECTURE            resnet50\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                200\n",
      "TRAIN_ROIS_PER_IMAGE           100\n",
      "USE_MINI_MASK                  False\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               5\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class InferenceConfig(Config):\n",
    "    # Set batch size to 1 since we'll be running inference on\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    NAME= \"myConfig\"\n",
    "    GPU_COUNT = 1\n",
    "    NUM_CLASSES = 2\n",
    "    IMAGES_PER_GPU = 1\n",
    "    IMAGE_MIN_DIM = 512 \n",
    "    IMAGE_MAX_DIM = 512 \n",
    "    USE_MINI_MASK = False\n",
    "    RESNET_ARCHITECTURE = \"resnet50\"\n",
    "    DETECTION_MAX_INSTANCES = 50\n",
    "    RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)\n",
    "    TRAIN_ROIS_PER_IMAGE = 100\n",
    "    STEPS_PER_EPOCH = 200\n",
    "    VALIDATION_STEPS = 5\n",
    "\n",
    "myconfig = InferenceConfig()\n",
    "myconfig.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n"
     ]
    }
   ],
   "source": [
    "# Build the inference model\n",
    "model = modellib.MaskRCNN(mode=\"inference\",\n",
    "                          config=inference_config,\n",
    "                          model_dir=train_log_dirpath)\n",
    "# Get path to saved weights. Either set a specific path or find last trained weights\n",
    "model_filepath = model_filepath if model_filepath else model.find_last()[1]\n",
    "#print(model_filepath)\n",
    "# Load trained weights (fill in path to trained weights here)\n",
    "assert model_filepath, \"Provide path to trained weights\"\n",
    "model.load_weights(model_filepath, by_name=True)\n",
    "print(\"Model loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['output_detections', 'output_mrcnn_class', 'output_mrcnn_bbox', 'output_mrcnn_mask', 'output_rois', 'output_rpn_class', 'output_rpn_bbox']\n"
     ]
    }
   ],
   "source": [
    "# Get keras model and save\n",
    "model_keras= model.keras_model\n",
    "# All new operations will be in test mode from now on.\n",
    "K.set_learning_phase(0)\n",
    "# Create output layer with customized names\n",
    "num_output = 7\n",
    "pred_node_names = [\"detections\", \"mrcnn_class\", \"mrcnn_bbox\", \"mrcnn_mask\",\n",
    "                       \"rois\", \"rpn_class\", \"rpn_bbox\"]\n",
    "pred_node_names = [\"output_\" + name for name in pred_node_names]\n",
    "print(pred_node_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 384 variables.\n",
      "Converted 384 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "pred = [tf.identity(model_keras.outputs[i], name = pred_node_names[i])\n",
    "        for i in range(num_output)]\n",
    "sess = K.get_session()\n",
    "# Get the object detection graph\n",
    "od_graph_def = graph_util.convert_variables_to_constants(sess,\n",
    "                                                         sess.graph.as_graph_def(),\n",
    "                                                         pred_node_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving frozen graph mask_rcnn_New.pb ...\n",
      "2450 ops in the frozen graph.\n"
     ]
    }
   ],
   "source": [
    "model_dirpath = os.path.dirname(model_filepath)\n",
    "pb_filepath = os.path.join(model_dirpath, filename)\n",
    "print('Saving frozen graph {} ...'.format(os.path.basename(pb_filepath)))\n",
    "\n",
    "frozen_graph_path = pb_filepath\n",
    "with tf.gfile.GFile(frozen_graph_path, 'wb') as f:\n",
    "    f.write(od_graph_def.SerializeToString())\n",
    "print('{} ops in the frozen graph.'.format(len(od_graph_def.node)))\n",
    "#print('pb file saved at', model_dirpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing model\n",
    "Now, we can load the model from the pb file and then use it to infere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mold_inputs(images):\n",
    "        \"\"\"Takes a list of images and modifies them to the format expected\n",
    "        as an input to the neural network.\n",
    "        images: List of image matricies [height,width,depth]. Images can have\n",
    "            different sizes.\n",
    "\n",
    "        Returns 3 Numpy matricies:\n",
    "        molded_images: [N, h, w, 3]. Images resized and normalized.\n",
    "        image_metas: [N, length of meta data]. Details about each image.\n",
    "        windows: [N, (y1, x1, y2, x2)]. The portion of the image that has the\n",
    "            original image (padding excluded).\n",
    "        \"\"\"\n",
    "        molded_images = []\n",
    "        image_metas = []\n",
    "        windows = []\n",
    "        print('IMAGE_PADDING: ',inference_config.IMAGE_PADDING)\n",
    "        for image in images:\n",
    "            # Resize image to fit the model expected size\n",
    "            # TODO: move resizing to mold_image()\n",
    "            molded_image, window, scale, padding = utils.resize_image(\n",
    "                image,\n",
    "                min_dim=inference_config.IMAGE_MIN_DIM,\n",
    "                max_dim=inference_config.IMAGE_MAX_DIM,\n",
    "                padding=inference_config.IMAGE_PADDING)\n",
    "            print(image.shape)\n",
    "            print('Image resized at: ', molded_image.shape)\n",
    "            print(window)\n",
    "            print(scale)\n",
    "            \"\"\"Takes RGB images with 0-255 values and subtraces\n",
    "                   the mean pixel and converts it to float. Expects image\n",
    "                   colors in RGB order.\"\"\"\n",
    "            molded_image = mold_image(molded_image, inference_config)\n",
    "            print('Image molded')\n",
    "            #print(a)\n",
    "            \"\"\"Takes attributes of an image and puts them in one 1D array.\"\"\"\n",
    "            image_meta = compose_image_meta(\n",
    "                0, image.shape, window,\n",
    "                np.zeros([inference_config.NUM_CLASSES], dtype=np.int32))\n",
    "            print('Meta of image prepared')\n",
    "            # Append\n",
    "            molded_images.append(molded_image)\n",
    "            windows.append(window)\n",
    "            image_metas.append(image_meta)\n",
    "        # Pack into arrays\n",
    "        molded_images = np.stack(molded_images)\n",
    "        image_metas = np.stack(image_metas)\n",
    "        windows = np.stack(windows)\n",
    "        return molded_images, image_metas, windows\n",
    "\n",
    "def mold_image(images, config):\n",
    "    return images.astype(np.float32) - config.MEAN_PIXEL\n",
    "\n",
    "def compose_image_meta(image_id, image_shape, window, active_class_ids):\n",
    "    \"\"\"Takes attributes of an image and puts them in one 1D array.\n",
    "\n",
    "    image_id: An int ID of the image. Useful for debugging.\n",
    "    image_shape: [height, width, channels]\n",
    "    window: (y1, x1, y2, x2) in pixels. The area of the image where the real\n",
    "            image is (excluding the padding)\n",
    "    active_class_ids: List of class_ids available in the dataset from which\n",
    "        the image came. Useful if training on images from multiple datasets\n",
    "        where not all classes are present in all datasets.\n",
    "    \"\"\"\n",
    "    meta = np.array(\n",
    "        [image_id] +            # size=1\n",
    "        list(image_shape) +     # size=3\n",
    "        list(window) +          # size=4 (y1, x1, y2, x2) in image cooredinates\n",
    "        list(active_class_ids)  # size=num_classes\n",
    "    )\n",
    "    return meta\n",
    "\n",
    "def unmold_detections(detections, mrcnn_mask, image_shape, window):\n",
    "    \"\"\"Reformats the detections of one image from the format of the neural\n",
    "    network output to a format suitable for use in the rest of the\n",
    "    application.\n",
    "\n",
    "    detections: [N, (y1, x1, y2, x2, class_id, score)]\n",
    "    mrcnn_mask: [N, height, width, num_classes]\n",
    "    image_shape: [height, width, depth] Original size of the image before resizing\n",
    "    window: [y1, x1, y2, x2] Box in the image where the real image is excluding the padding.\n",
    "\n",
    "        Returns:\n",
    "        boxes: [N, (y1, x1, y2, x2)] Bounding boxes in pixels\n",
    "        class_ids: [N] Integer class IDs for each bounding box\n",
    "        scores: [N] Float probability scores of the class_id\n",
    "        masks: [height, width, num_instances] Instance masks\n",
    "        \"\"\"\n",
    "    # How many detections do we have?\n",
    "    # Detections array is padded with zeros. Find the first class_id == 0.\n",
    "    zero_ix = np.where(detections[:, 4] == 0)[0]\n",
    "    N = zero_ix[0] if zero_ix.shape[0] > 0 else detections.shape[0]\n",
    "    print('Number of detections: ',N)\n",
    "    print('Window: ',window)\n",
    "    # Extract boxes, class_ids, scores, and class-specific masks\n",
    "    boxes = detections[:N, :4]\n",
    "    print('boxes',boxes.shape,' ',boxes)\n",
    "    class_ids = detections[:N, 4].astype(np.int32)\n",
    "    print('Class_ids: ',class_ids.shape,' ',class_ids)\n",
    "    scores = detections[:N, 5]\n",
    "    print('Scores: ',scores.shape,' ',scores)\n",
    "    masks = mrcnn_mask[np.arange(N), :, :, class_ids]\n",
    "    print('Masks: ',masks.shape)# masks)\n",
    "    # Compute scale and shift to translate coordinates to image domain.\n",
    "    print(image_shape[0])\n",
    "    print(window[2] - window[0])\n",
    "    h_scale = image_shape[0] / (window[2] - window[0])\n",
    "    print('h_scale: ',h_scale)\n",
    "    w_scale = image_shape[1] / (window[3] - window[1])\n",
    "    print('w_scale: ',w_scale)\n",
    "    scale = min(h_scale, w_scale)\n",
    "    shift = window[:2]  # y, x\n",
    "    print('shift: ',shift)\n",
    "    scales = np.array([scale, scale, scale, scale])\n",
    "    print('scales: ',scales)\n",
    "    shifts = np.array([shift[0], shift[1], shift[0], shift[1]])\n",
    "    print('shifts: ',shifts)\n",
    "    # Translate bounding boxes to image domain\n",
    "    boxes = np.multiply(boxes - shifts, scales).astype(np.int32)\n",
    "    print('boxes: ',boxes.shape,' ',boxes)\n",
    "    # Filter out detections with zero area. Often only happens in early\n",
    "    # stages of training when the network weights are still a bit random.\n",
    "    exclude_ix = np.where(\n",
    "        (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1]) <= 0)[0]\n",
    "    if exclude_ix.shape[0] > 0:\n",
    "        boxes = np.delete(boxes, exclude_ix, axis=0)\n",
    "        class_ids = np.delete(class_ids, exclude_ix, axis=0)\n",
    "        scores = np.delete(scores, exclude_ix, axis=0)\n",
    "        masks = np.delete(masks, exclude_ix, axis=0)\n",
    "        N = class_ids.shape[0]\n",
    "\n",
    "    # Resize masks to original image size and set boundary threshold.\n",
    "    full_masks = []\n",
    "    for i in range(N):\n",
    "        # Convert neural network mask to full size mask\n",
    "        full_mask = utils.unmold_mask(masks[i], boxes[i], image_shape)\n",
    "        full_masks.append(full_mask)\n",
    "    full_masks = np.stack(full_masks, axis=-1)\\\n",
    "        if full_masks else np.empty((0,) + masks.shape[1:3])\n",
    "\n",
    "    return boxes, class_ids, scores, full_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph loaded.\n",
      "Image loaded.\n",
      "Processing 1 images\n",
      "image            shape: (256, 256, 3)         min:       2.00  max:     251.00\n",
      "RGB image loaded and preprocessed.\n",
      "IMAGE_PADDING:  True\n",
      "(256, 256, 3)\n",
      "Image resized at:  (512, 512, 3)\n",
      "(0, 0, 512, 512)\n",
      "2.0\n",
      "Image molded\n",
      "Meta of image prepared\n",
      "(1, 512, 512, 3)\n",
      "Images meta:  [[  0 256 256   3   0   0 512 512   0   0]]\n",
      "Tensor(\"input_image:0\", shape=(?, 512, 512, 3), dtype=float32)\n",
      "Tensor(\"input_image_meta:0\", shape=(?, ?), dtype=float32)\n",
      "Found  Tensor(\"output_detections:0\", shape=(1, 50, 6), dtype=float32)\n",
      "Found  Tensor(\"output_mrcnn_class:0\", shape=(?, 1000, 2), dtype=float32)\n",
      "Found  Tensor(\"output_mrcnn_bbox:0\", shape=(?, 1000, 2, 4), dtype=float32)\n",
      "Found  Tensor(\"output_mrcnn_mask:0\", shape=(?, 50, 28, 28, 2), dtype=float32)\n",
      "Found  Tensor(\"output_rois:0\", shape=(1, ?, ?), dtype=float32)\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value bn5b_branch2a/moving_mean\n\t [[Node: bn5b_branch2a/moving_mean/read = Identity[T=DT_FLOAT, _class=[\"loc:@bn5b_branch2a/moving_mean\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](bn5b_branch2a/moving_mean)]]\n\t [[Node: mrcnn_detection/map/while/strided_slice/_139 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_2386_mrcnn_detection/map/while/strided_slice\", tensor_type=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](^_cloopmrcnn_detection/map/while/PadV2/constant_values/_1)]]\n\nCaused by op 'bn5b_branch2a/moving_mean/read', defined at:\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tornado\\ioloop.py\", line 832, in start\n    self._run_callback(self._callbacks.popleft())\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tornado\\ioloop.py\", line 605, in _run_callback\n    ret = callback()\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-5-1d9768016075>\", line 4, in <module>\n    model_dir=train_log_dirpath)\n  File \"C:\\Users\\ADMIN\\Mask\\def_single\\model.py\", line 1770, in __init__\n    self.keras_model = self.build(mode=mode, config=config)\n  File \"C:\\Users\\ADMIN\\Mask\\def_single\\model.py\", line 1827, in build\n    _, C2, C3, C4, C5 = resnet_graph(input_image,\"resnet50\", stage5=True)\n  File \"C:\\Users\\ADMIN\\Mask\\def_single\\model.py\", line 180, in resnet_graph\n    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n  File \"C:\\Users\\ADMIN\\Mask\\def_single\\model.py\", line 98, in identity_block\n    x = BatchNorm(axis=3, name=bn_name_base + '2a')(x)\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\keras\\engine\\topology.py\", line 590, in __call__\n    self.build(input_shapes[0])\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\keras\\layers\\normalization.py\", line 122, in build\n    trainable=False)\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\keras\\legacy\\interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\keras\\engine\\topology.py\", line 414, in add_weight\n    constraint=constraint)\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 392, in variable\n    v = tf.Variable(value, dtype=tf.as_dtype(dtype), name=name)\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 229, in __init__\n    constraint=constraint)\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 376, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 127, in identity\n    return gen_array_ops.identity(input, name=name)\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 2728, in identity\n    \"Identity\", input=input, name=name)\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value bn5b_branch2a/moving_mean\n\t [[Node: bn5b_branch2a/moving_mean/read = Identity[T=DT_FLOAT, _class=[\"loc:@bn5b_branch2a/moving_mean\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](bn5b_branch2a/moving_mean)]]\n\t [[Node: mrcnn_detection/map/while/strided_slice/_139 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_2386_mrcnn_detection/map/while/strided_slice\", tensor_type=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](^_cloopmrcnn_detection/map/while/PadV2/constant_values/_1)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1349\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1329\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    474\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value bn5b_branch2a/moving_mean\n\t [[Node: bn5b_branch2a/moving_mean/read = Identity[T=DT_FLOAT, _class=[\"loc:@bn5b_branch2a/moving_mean\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](bn5b_branch2a/moving_mean)]]\n\t [[Node: mrcnn_detection/map/while/strided_slice/_139 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_2386_mrcnn_detection/map/while/strided_slice\", tensor_type=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](^_cloopmrcnn_detection/map/while/PadV2/constant_values/_1)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-249ccbda8a9b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Found '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroisT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[0mdetections\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdetectionsT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mimg_ph\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmolded_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_meta_ph\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mimage_metas\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;31m#print('Detections: ',detections[0].shape, detections[0])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[0mmrcnn_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmrcnn_classT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mimg_ph\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmolded_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_meta_ph\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mimage_metas\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1126\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1128\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1129\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1344\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1345\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1362\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1363\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1365\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value bn5b_branch2a/moving_mean\n\t [[Node: bn5b_branch2a/moving_mean/read = Identity[T=DT_FLOAT, _class=[\"loc:@bn5b_branch2a/moving_mean\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](bn5b_branch2a/moving_mean)]]\n\t [[Node: mrcnn_detection/map/while/strided_slice/_139 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_2386_mrcnn_detection/map/while/strided_slice\", tensor_type=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](^_cloopmrcnn_detection/map/while/PadV2/constant_values/_1)]]\n\nCaused by op 'bn5b_branch2a/moving_mean/read', defined at:\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tornado\\ioloop.py\", line 832, in start\n    self._run_callback(self._callbacks.popleft())\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tornado\\ioloop.py\", line 605, in _run_callback\n    ret = callback()\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-5-1d9768016075>\", line 4, in <module>\n    model_dir=train_log_dirpath)\n  File \"C:\\Users\\ADMIN\\Mask\\def_single\\model.py\", line 1770, in __init__\n    self.keras_model = self.build(mode=mode, config=config)\n  File \"C:\\Users\\ADMIN\\Mask\\def_single\\model.py\", line 1827, in build\n    _, C2, C3, C4, C5 = resnet_graph(input_image,\"resnet50\", stage5=True)\n  File \"C:\\Users\\ADMIN\\Mask\\def_single\\model.py\", line 180, in resnet_graph\n    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n  File \"C:\\Users\\ADMIN\\Mask\\def_single\\model.py\", line 98, in identity_block\n    x = BatchNorm(axis=3, name=bn_name_base + '2a')(x)\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\keras\\engine\\topology.py\", line 590, in __call__\n    self.build(input_shapes[0])\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\keras\\layers\\normalization.py\", line 122, in build\n    trainable=False)\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\keras\\legacy\\interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\keras\\engine\\topology.py\", line 414, in add_weight\n    constraint=constraint)\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 392, in variable\n    v = tf.Variable(value, dtype=tf.as_dtype(dtype), name=name)\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 229, in __init__\n    constraint=constraint)\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 376, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 127, in identity\n    return gen_array_ops.identity(input, name=name)\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 2728, in identity\n    \"Identity\", input=input, name=name)\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"c:\\programdata\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value bn5b_branch2a/moving_mean\n\t [[Node: bn5b_branch2a/moving_mean/read = Identity[T=DT_FLOAT, _class=[\"loc:@bn5b_branch2a/moving_mean\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](bn5b_branch2a/moving_mean)]]\n\t [[Node: mrcnn_detection/map/while/strided_slice/_139 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_2386_mrcnn_detection/map/while/strided_slice\", tensor_type=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](^_cloopmrcnn_detection/map/while/PadV2/constant_values/_1)]]\n"
     ]
    }
   ],
   "source": [
    "with tf.gfile.FastGFile(pb_filepath, 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        _ = tf.import_graph_def(graph_def, name='')\n",
    "print('Graph loaded.')\n",
    "testImage =os.path.join(ROOT_DIR,'model','150_256.jpg') #image of the size defined in the config\n",
    "sess = tf.InteractiveSession()\n",
    "image = imageio.imread(testImage)\n",
    "print('Image loaded.')\n",
    "images = [image]\n",
    "print(\"Processing {} images\".format(len(images)))\n",
    "for im in images:\n",
    "    modellib.log(\"image\", im)\n",
    "print('RGB image loaded and preprocessed.')\n",
    "molded_images, image_metas, windows = mold_inputs(images)\n",
    "print(molded_images.shape)\n",
    "print('Images meta: ',image_metas)\n",
    "img_ph = sess.graph.get_tensor_by_name('input_image:0')\n",
    "print(img_ph)\n",
    "img_meta_ph = sess.graph.get_tensor_by_name('input_image_meta:0')\n",
    "print(img_meta_ph)\n",
    "detectionsT = sess.graph.get_tensor_by_name('output_detections:0')\n",
    "print('Found ',detectionsT)\n",
    "mrcnn_classT = sess.graph.get_tensor_by_name('output_mrcnn_class:0')\n",
    "print('Found ',mrcnn_classT)\n",
    "mrcnn_bboxT = sess.graph.get_tensor_by_name('output_mrcnn_bbox:0')\n",
    "print('Found ', mrcnn_bboxT)\n",
    "mrcnn_maskT = sess.graph.get_tensor_by_name('output_mrcnn_mask:0')\n",
    "print('Found ', mrcnn_maskT)\n",
    "roisT = sess.graph.get_tensor_by_name('output_rois:0')\n",
    "print('Found ', roisT)\n",
    "        \n",
    "detections = sess.run(detectionsT, feed_dict={img_ph: molded_images, img_meta_ph: image_metas})\n",
    "#print('Detections: ',detections[0].shape, detections[0])\n",
    "mrcnn_class = sess.run(mrcnn_classT, feed_dict={img_ph: molded_images, img_meta_ph: image_metas})\n",
    "#print('Classes: ',mrcnn_class[0].shape, mrcnn_class[0])\n",
    "mrcnn_bbox = sess.run(mrcnn_bboxT, feed_dict={img_ph: molded_images, img_meta_ph: image_metas})\n",
    "#print('BBoxes: ',mrcnn_bbox[0].shape, mrcnn_bbox[0])\n",
    "mrcnn_mask = sess.run(mrcnn_maskT, feed_dict={img_ph: molded_images, img_meta_ph: image_metas})\n",
    "#print('Masks: ',mrcnn_mask[0].shape )#, outputs1[0])\n",
    "rois = sess.run(roisT, feed_dict={img_ph: molded_images, img_meta_ph: image_metas})\n",
    "#print('Rois: ',rois[0].shape, rois[0])\n",
    "\n",
    "results = []\n",
    "for i, image in enumerate(images):\n",
    "    print('Calculating results for image#',i)\n",
    "    final_rois, final_class_ids, final_scores, final_masks =\\\n",
    "    unmold_detections(detections[i], mrcnn_mask[i],\n",
    "                                    image.shape, windows[i])\n",
    "    results.append({\n",
    "        \"rois\": final_rois,\n",
    "        \"class_ids\": final_class_ids,\n",
    "        \"scores\": final_scores,\n",
    "        \"masks\": final_masks,\n",
    "    })\n",
    "r = results[0]\n",
    "#print(r)\n",
    "print (r['scores'][0])\n",
    "print (r['class_ids'][0])\n",
    "print (r['rois'][0])\n",
    "print (r['masks'][0].shape)\n",
    "\n",
    "class_names = [\"BG\",\"nuclei\"]\n",
    "visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], class_names, r['scores'], ax=get_ax())\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
